{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"12413f13-b25d-4b0c-a2ec-64876997fef6","_cell_guid":"cb3ea9f3-6fe6-4d80-99c8-cf3d02f4d331","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:40:54.938322Z","iopub.execute_input":"2024-12-06T10:40:54.939078Z","iopub.status.idle":"2024-12-06T10:40:55.253087Z","shell.execute_reply.started":"2024-12-06T10:40:54.939044Z","shell.execute_reply":"2024-12-06T10:40:55.252400Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# ============================================================================\n# Section 1: Environment Setup and Package Installation\n# ============================================================================\n\"\"\"\nThis section configures our training environment and imports necessary libraries.\nWe're using Kaggle's T4×2 GPU setup which provides:\n- 2 NVIDIA T4 GPUs with 16GB memory each (32GB total)\n- 4 CPU cores\n- 29GB RAM\n\"\"\"\n\n\"\"\"\nFirst, we need to install the necessary libraries for our experiment.\nThese packages provide the foundation for working with transformers and datasets.\n\"\"\"\n\n# Install required packages\n!pip install transformers datasets torch numpy pandas tqdm wandb\n\n# Core data science and numerical computation libraries\nimport numpy as np  # For numerical operations and array handling\nimport pandas as pd # For data manipulation and analysis\n\n# PyTorch and its ecosystem\nimport torch  # Deep learning framework\nfrom torch.utils.data import Dataset, DataLoader  # Data handling utilities\n\n# Transformers libraries\nfrom transformers import (\n    DistilBertTokenizer,  # For text tokenization\n    DistilBertForSequenceClassification,  # The main model\n    AdamW,  # Optimizer with weight decay fix\n    get_linear_schedule_with_warmup  # Learning rate scheduler\n)\n\n# Metrics and utilities\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nimport time\nfrom tqdm import tqdm  # For progress bars\nimport wandb  # For experiment tracking\nimport random  # For reproducibility\nimport os  # For file operations\n\n# Set random seeds for reproducibility\ndef set_seeds(seed=42):\n    \"\"\"\n    Set random seeds for reproducible results across multiple runs.\n    Args:\n        seed (int): Seed value for random number generators\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nset_seeds()\n\n# Configure GPU setup\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nif torch.cuda.is_available():\n    print(f\"Using {torch.cuda.device_count()} GPU(s):\")\n    for i in range(torch.cuda.device_count()):\n        print(f\"  - {torch.cuda.get_device_name(i)}\")\nelse:\n    print(\"Using CPU\")","metadata":{"_uuid":"bb1f256d-0389-4dfd-a2ea-fad18d02d17e","_cell_guid":"eceb401d-7504-49e9-88bc-98e5d4a566f4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:40:55.254656Z","iopub.execute_input":"2024-12-06T10:40:55.255005Z","iopub.status.idle":"2024-12-06T10:41:24.788637Z","shell.execute_reply.started":"2024-12-06T10:40:55.254977Z","shell.execute_reply":"2024-12-06T10:41:24.787734Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nRequirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.18.7)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.43)\nRequirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from wandb) (3.11.0)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.19.0)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (70.0.0)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\nUsing 2 GPU(s):\n  - Tesla T4\n  - Tesla T4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ============================================================================\n# Section 2: Dataset Loading and Initial Setup\n# ============================================================================\n\"\"\"\nThe AG News dataset contains news articles categorized into four classes:\n1. World News\n2. Sports\n3. Business\n4. Science/Technology\n\nEach article has a title and description, which we'll use for classification.\n\"\"\"\n\n# Import the dataset handling library\nfrom datasets import load_dataset\n\n# Load the AG News dataset\n# This command downloads and caches the dataset locally\n# The dataset is split into 'train' and 'test' sets automatically\ndataset = load_dataset(\"ag_news\")\n\n# Print dataset information\nprint(\"\\nDataset Overview:\")\nprint(f\"Training examples: {len(dataset['train'])}\")\nprint(f\"Test examples: {len(dataset['test'])}\")\n\n# Initialize the DistilBERT tokenizer\n# 'distilbert-base-uncased' is a smaller, faster version of BERT\n# 'uncased' means it converts all text to lowercase, which helps with consistency\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n\n# Display a sample from the dataset\nprint(\"\\nSample article:\")\nsample = dataset['train'][0]\nprint(f\"Text: {sample['text']}\")\nprint(f\"Label: {sample['label']}\")","metadata":{"_uuid":"b92c3ba7-703e-4a56-bbec-95f5dac99663","_cell_guid":"9ef876fa-dea8-4db0-8f97-72b427b76018","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:41:24.790162Z","iopub.execute_input":"2024-12-06T10:41:24.790889Z","iopub.status.idle":"2024-12-06T10:41:28.631347Z","shell.execute_reply.started":"2024-12-06T10:41:24.790840Z","shell.execute_reply":"2024-12-06T10:41:28.630642Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4498ba2a32c247fb974e0e9bd40cf4d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"751f663b739444ef9e4fffa1d75e3a6f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02644d5076af467f89626b77e2304ae7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e6e1f529ad447a496ae370b98dee10a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"049fa92d80d74b93975f99a6a74ad011"}},"metadata":{}},{"name":"stdout","text":"\nDataset Overview:\nTraining examples: 120000\nTest examples: 7600\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bfa579e22a64bec885d10c41935fb76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb2104ddab7441549e1228a6b1bd65dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cde1ee1ede314a3098b887fad1c784e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c196f9650caf41eb85080e78b09463c6"}},"metadata":{}},{"name":"stdout","text":"\nSample article:\nText: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\nLabel: 2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ============================================================================\n# Section 3: Data Preprocessing Functions\n# ============================================================================\ndef tokenize_and_format(examples):\n    \"\"\"\n    Convert text examples into a format suitable for DistilBERT processing.\n    \n    This function has been enhanced to preserve label information, which is\n    crucial for our classification task. Without preserving labels, we'd lose\n    our training targets.\n    \n    This function performs several key operations:\n    1. Takes a batch of text examples\n    2. Tokenizes them (splits into subwords)\n    3. Adds special tokens like [CLS] and [SEP]\n    4. Pads all sequences to the same length\n    5. Preserves the original labels\n    6. Creates attention masks to indicate real vs padding tokens\n    \n    Parameters:\n        examples: A batch of text examples from our dataset\n        \n    Returns:\n        A dictionary containing:\n        - input_ids: The numerical representations of our tokens\n        - attention_mask: Binary mask (1 for real tokens, 0 for padding)\n        - labels: The classification category for each example\n    \"\"\"\n    # First, tokenize the texts\n    tokenized = tokenizer(\n        examples['text'],\n        padding='max_length',    \n        truncation=True,         \n        max_length=128          \n    )\n    \n    # Preserve the labels by adding them to the tokenized output\n    tokenized['labels'] = examples['label']\n    \n    return tokenized","metadata":{"_uuid":"38edf1ca-814e-436e-8f85-ba6be6463d11","_cell_guid":"ad41c4f2-230a-4698-bc7b-26aac0de047c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:41:28.633898Z","iopub.execute_input":"2024-12-06T10:41:28.634860Z","iopub.status.idle":"2024-12-06T10:41:28.640022Z","shell.execute_reply.started":"2024-12-06T10:41:28.634816Z","shell.execute_reply":"2024-12-06T10:41:28.639190Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# ============================================================================\n# Section 4: Dataset Processing\n# ============================================================================\n\n# Process the training dataset\n# map() applies our tokenization function to the entire dataset efficiently\n# batched=True processes multiple examples at once for speed\n\nprint(\"Tokenizing training data...\")\ntrain_dataset = dataset['train'].map(\n    tokenize_and_format,  # Note we're using the new function name\n    batched=True,\n    remove_columns=dataset['train'].column_names\n)\n\nprint(\"Tokenizing test data...\")\ntest_dataset = dataset['test'].map(\n    tokenize_and_format,  # Note we're using the new function name\n    batched=True,\n    remove_columns=dataset['test'].column_names\n)","metadata":{"_uuid":"230eff8b-4718-4992-9cc5-b48883feaa7f","_cell_guid":"2e768fde-2cf9-4231-9ef2-c4a0821af5ba","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:41:28.641178Z","iopub.execute_input":"2024-12-06T10:41:28.641433Z","iopub.status.idle":"2024-12-06T10:43:18.529179Z","shell.execute_reply.started":"2024-12-06T10:41:28.641407Z","shell.execute_reply":"2024-12-06T10:43:18.528337Z"}},"outputs":[{"name":"stdout","text":"Tokenizing training data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4f9335039e644079763a389728b7b41"}},"metadata":{}},{"name":"stdout","text":"Tokenizing test data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29764b70910c414eb37d39e29ceffae7"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# ============================================================================\n# Section 5: Format Conversion for PyTorch\n# ============================================================================\n\n\"\"\"\nThe final step in our data preparation pipeline is converting our processed\ndatasets into a format that PyTorch can use for training. This involves:\n1. Converting our numerical data to PyTorch tensors\n2. Specifying which columns we want to keep\n3. Setting up the data format for efficient loading during training\n\nThe columns we need are:\n- input_ids: The numerical representations of our tokens\n- attention_mask: Shows which tokens are real vs padding\n- label: The classification category (0-3) for each article\n\"\"\"\n\n# Convert training data to PyTorch format\ntrain_dataset.set_format(\n    type='torch',              # Convert to PyTorch tensors\n    columns=[\n        'input_ids',           # The tokenized text\n        'attention_mask',      # Mask showing real tokens vs padding\n        'labels'               # Classification category\n    ]\n)\n\n# Convert test data to PyTorch format\ntest_dataset.set_format(\n    type='torch',              # Convert to PyTorch tensors\n    columns=[\n        'input_ids',           # The tokenized text\n        'attention_mask',      # Mask showing real tokens vs padding\n        'labels'               # Classification category\n    ]\n)\n\nprint(\"Dataset preparation completed!\")\nprint(f\"Training examples: {len(train_dataset)}\")\nprint(f\"Test examples: {len(test_dataset)}\")","metadata":{"_uuid":"78c7de78-d0fe-46d6-9147-9dfd95d83bbd","_cell_guid":"ade2825e-bfb0-42be-85e9-2a2718cf7e1f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:43:18.530485Z","iopub.execute_input":"2024-12-06T10:43:18.531396Z","iopub.status.idle":"2024-12-06T10:43:18.538054Z","shell.execute_reply.started":"2024-12-06T10:43:18.531364Z","shell.execute_reply":"2024-12-06T10:43:18.537147Z"}},"outputs":[{"name":"stdout","text":"Dataset preparation completed!\nTraining examples: 120000\nTest examples: 7600\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ============================================================================\n# Section 6: Model Configuration and Initialization\n# ============================================================================\n\"\"\"\nIn this section, we set up our DistilBERT model for text classification.\nThis involves configuring the model architecture and setting appropriate \nhyperparameters for our AG News classification task.\n\nKey hyperparameters are chosen based on:\n1. Dataset characteristics (AG News with 4 classes)\n2. Hardware constraints (T4×2 GPU setup)\n3. Best practices for text classification tasks\n\"\"\"\n\n# Initialize the DistilBERT model with classification head\n# num_labels=4 because AG News has 4 categories: World, Sports, Business, Sci/Tech\nmodel = DistilBertForSequenceClassification.from_pretrained(\n    'distilbert-base-uncased',  # Using the base uncased model\n    num_labels=4,               # Number of classification categories\n    return_dict=True            # Returns outputs as a dictionary for easier handling\n)\n\n# Move model to GPU(s)\n# If multiple GPUs are available, we'll use DataParallel for multi-GPU training\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = torch.nn.DataParallel(model)  # Wrap model for multi-GPU use\nmodel = model.to(device)  # Move model to GPU(s) or CPU\n\n# Print model architecture and parameter count\nprint(\"\\nModel Architecture:\")\nprint(model)\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"\\nTotal parameters: {total_params:,}\")\nprint(f\"Trainable parameters: {trainable_params:,}\")","metadata":{"_uuid":"dbd5127c-3f92-410d-b9ba-230c82b2738a","_cell_guid":"3ac89dae-a152-4cfb-9e32-45dc0717cce9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:43:18.539276Z","iopub.execute_input":"2024-12-06T10:43:18.539822Z","iopub.status.idle":"2024-12-06T10:43:20.395630Z","shell.execute_reply.started":"2024-12-06T10:43:18.539781Z","shell.execute_reply":"2024-12-06T10:43:20.394734Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f87f76ed186a4c8bb2c00db5279f56cf"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Using 2 GPUs!\n\nModel Architecture:\nDataParallel(\n  (module): DistilBertForSequenceClassification(\n    (distilbert): DistilBertModel(\n      (embeddings): Embeddings(\n        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n        (position_embeddings): Embedding(512, 768)\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (transformer): Transformer(\n        (layer): ModuleList(\n          (0-5): 6 x TransformerBlock(\n            (attention): DistilBertSdpaAttention(\n              (dropout): Dropout(p=0.1, inplace=False)\n              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n            )\n            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (ffn): FFN(\n              (dropout): Dropout(p=0.1, inplace=False)\n              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n              (activation): GELUActivation()\n            )\n            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          )\n        )\n      )\n    )\n    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n    (classifier): Linear(in_features=768, out_features=4, bias=True)\n    (dropout): Dropout(p=0.2, inplace=False)\n  )\n)\n\nTotal parameters: 66,956,548\nTrainable parameters: 66,956,548\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ============================================================================\n# Section 7: Training Configuration\n# ============================================================================\n\"\"\"\nThis section defines the training hyperparameters and optimization settings.\nThese parameters are crucial for effective model training and have been\nchosen based on empirical testing and hardware constraints.\n\"\"\"\n\n# Training Hyperparameters\ntrain_config = {\n    'batch_size': 32,          # Balanced for T4 GPU memory\n    'epochs': 5,               # Number of complete passes through the dataset\n    'learning_rate': 2e-5,     # Standard for fine-tuning transformer models\n    'warmup_steps': 500,       # Gradually increases learning rate at start\n    'weight_decay': 0.01,      # L2 regularization to prevent overfitting\n    'max_grad_norm': 1.0,      # Clips gradients to prevent explosive gradients\n    'logging_steps': 100       # How often to log metrics during training\n}\n\n# Create DataLoader for batched training\n# DataLoader handles batching and shuffling of the dataset\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=train_config['batch_size'],\n    shuffle=True,              # Shuffles data every epoch\n    num_workers=0,             # Number of CPU processes for data loading, Changed from 2 to 0 to avoid fork issues\n    pin_memory=True           # Speeds up data transfer to GPU\n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=train_config['batch_size'],\n    shuffle=False,             # No need to shuffle test data\n    num_workers=0,\n    pin_memory=True\n)\n\n# Initialize the optimizer with AdamW\n# AdamW is Adam with proper weight decay implementation\noptimizer = AdamW(\n    model.parameters(),\n    lr=train_config['learning_rate'],\n    weight_decay=train_config['weight_decay']\n)\n\n# Create learning rate scheduler\n# Linear schedule with warmup helps stabilize early training\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=train_config['warmup_steps'],\n    num_training_steps=len(train_loader) * train_config['epochs']\n)\n\n# Initialize WandB for experiment tracking - api key -  7915f42557c966f4cec28fc504eeb9d4b1427fad\nwandb.init(\n    project=\"ag-news-classification\",\n    name=\"distilbert-baseline\",\n    config=train_config\n)","metadata":{"_uuid":"8ec6963a-386b-4e42-8d36-729c81931923","_cell_guid":"63a230e0-0e55-4889-bab8-419005db4337","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:43:20.396699Z","iopub.execute_input":"2024-12-06T10:43:20.396946Z","iopub.status.idle":"2024-12-06T10:43:35.642269Z","shell.execute_reply.started":"2024-12-06T10:43:20.396921Z","shell.execute_reply":"2024-12-06T10:43:35.641415Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241206_104334-3mlf6inp</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/shivayshakti2025-nasa/ag-news-classification/runs/3mlf6inp' target=\"_blank\">distilbert-baseline</a></strong> to <a href='https://wandb.ai/shivayshakti2025-nasa/ag-news-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/shivayshakti2025-nasa/ag-news-classification' target=\"_blank\">https://wandb.ai/shivayshakti2025-nasa/ag-news-classification</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/shivayshakti2025-nasa/ag-news-classification/runs/3mlf6inp' target=\"_blank\">https://wandb.ai/shivayshakti2025-nasa/ag-news-classification/runs/3mlf6inp</a>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/html":"<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/shivayshakti2025-nasa/ag-news-classification/runs/3mlf6inp?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>","text/plain":"<wandb.sdk.wandb_run.Run at 0x7fe9554f4cd0>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# ============================================================================\n# Section 8: Training Loop Implementation (Fixed for Multi-GPU)\n# ============================================================================\n\"\"\"\nModified training loop to properly handle loss computation with DataParallel\nacross multiple GPUs. The key changes include:\n1. Proper loss reduction across GPUs\n2. Corrected gradient computation\n3. Enhanced error handling for multi-GPU setup\n\"\"\"\n\ndef train_epoch(model, train_loader, optimizer, scheduler, epoch):\n    \"\"\"\n    Trains the model for one epoch with multi-GPU support.\n    \n    Key modifications:\n    - Properly handles loss reduction across multiple GPUs\n    - Ensures correct gradient computation\n    - Adds robust error checking for GPU operations\n    \n    Args:\n        model: The DistilBERT model (potentially wrapped in DataParallel)\n        train_loader: DataLoader containing training batches\n        optimizer: The AdamW optimizer\n        scheduler: Learning rate scheduler\n        epoch: Current epoch number\n    \n    Returns:\n        average_loss: Mean loss value for the epoch\n    \"\"\"\n    # Set model to training mode\n    model.train()\n    \n    # Initialize tracking variables\n    total_loss = 0\n    total_steps = len(train_loader)\n    \n    # Progress bar for visualization\n    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch + 1}')\n    \n    for step, batch in enumerate(progress_bar):\n        try:\n            # Move batch to GPU/CPU\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            # Clear gradients\n            optimizer.zero_grad()\n            \n            # Forward pass\n            # Note: When using DataParallel, loss needs to be handled carefully\n            outputs = model(\n                input_ids=batch['input_ids'],\n                attention_mask=batch['attention_mask'],\n                labels=batch['labels']\n            )\n            \n            # Get loss - ensuring it's a scalar\n            # Important: This handles the multi-GPU case properly\n            loss = outputs.loss.mean() if torch.cuda.device_count() > 1 else outputs.loss\n            \n            # Backward pass\n            loss.backward()\n            \n            # Gradient clipping\n            torch.nn.utils.clip_grad_norm_(\n                model.parameters(), \n                train_config['max_grad_norm']\n            )\n            \n            # Update parameters\n            optimizer.step()\n            scheduler.step()\n            \n            # Update tracking\n            total_loss += loss.item()\n            current_loss = total_loss / (step + 1)\n            \n            # Update progress bar\n            progress_bar.set_description(\n                f'Epoch {epoch + 1} - Loss: {current_loss:.4f}'\n            )\n            \n            # Log to WandB\n            if step % train_config['logging_steps'] == 0:\n                wandb.log({\n                    'batch_loss': loss.item(),\n                    'average_loss': current_loss,\n                    'learning_rate': scheduler.get_last_lr()[0],\n                    'epoch': epoch,\n                    'step': step\n                })\n                \n        except RuntimeError as e:\n            print(f\"\\nError in batch processing: {str(e)}\")\n            print(f\"Batch size: {batch['input_ids'].size()}\")\n            print(f\"GPU memory allocated: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n            raise e\n    \n    return total_loss / total_steps","metadata":{"_uuid":"67e4a357-2316-4c10-8d45-e3262bff5477","_cell_guid":"f989688e-0d36-4226-a4ff-f999d844b722","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:43:35.643643Z","iopub.execute_input":"2024-12-06T10:43:35.644130Z","iopub.status.idle":"2024-12-06T10:43:35.654973Z","shell.execute_reply.started":"2024-12-06T10:43:35.644089Z","shell.execute_reply":"2024-12-06T10:43:35.654149Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# ============================================================================\n# Section 9: Evaluation Function\n# ============================================================================\n\"\"\"\nThis section defines the evaluation function that assesses model performance\non the validation/test set. It computes various metrics including:\n- Accuracy\n- F1 Score\n- Precision\n- Recall\n\nThese metrics provide a comprehensive view of model performance across\nall classification categories.\n\"\"\"\n\ndef evaluate(model, eval_loader):\n    \"\"\"\n    Evaluates the model on validation/test data with proper multi-GPU support.\n    \n    The key modifications address tensor handling for multi-GPU setups by:\n    1. Properly reducing predictions from multiple GPUs\n    2. Ensuring correct loss aggregation\n    3. Handling tensor gathering across devices\n    \n    Args:\n        model: The DistilBERT model (potentially wrapped in DataParallel)\n        eval_loader: DataLoader containing evaluation batches\n    \n    Returns:\n        dict: Dictionary containing various performance metrics\n    \"\"\"\n    model.eval()\n    all_predictions = []\n    all_labels = []\n    total_eval_loss = 0\n    \n    with torch.no_grad():\n        for batch in tqdm(eval_loader, desc='Evaluating'):\n            # Move batch to GPU\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            # Forward pass\n            outputs = model(\n                input_ids=batch['input_ids'],\n                attention_mask=batch['attention_mask'],\n                labels=batch['labels']\n            )\n            \n            # Handle multi-GPU loss reduction\n            loss = outputs.loss.mean() if torch.cuda.device_count() > 1 else outputs.loss\n            total_eval_loss += loss.item()\n            \n            # Handle multi-GPU logits\n            logits = outputs.logits\n            if torch.cuda.device_count() > 1:\n                # If using DataParallel, logits will be scattered across GPUs\n                # We need to gather them properly\n                logits = logits.view(batch['input_ids'].size(0), -1)\n\n            # Add debugging print statement here\n            print(f\"Logits shape: {logits.shape}, Labels shape: {batch['labels'].shape}\")\n            \n            # Get predictions\n            predictions = torch.argmax(logits, dim=-1)\n            \n            # Move predictions and labels to CPU for metric calculation\n            predictions = predictions.cpu()\n            labels = batch['labels'].cpu()\n            \n            all_predictions.extend(predictions.numpy())\n            all_labels.extend(labels.numpy())\n    \n    # Calculate metrics\n    metrics = {\n        'eval_loss': total_eval_loss / len(eval_loader),\n        'accuracy': accuracy_score(all_labels, all_predictions),\n        'f1': f1_score(all_labels, all_predictions, average='weighted'),\n        'precision': precision_score(all_labels, all_predictions, average='weighted'),\n        'recall': recall_score(all_labels, all_predictions, average='weighted')\n    }\n    \n    return metrics","metadata":{"_uuid":"e26fc3f5-2dd3-4b98-a3b2-af057e681ae3","_cell_guid":"667eeb4a-988a-4c67-a262-e181d979e1ae","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:43:35.657539Z","iopub.execute_input":"2024-12-06T10:43:35.657886Z","iopub.status.idle":"2024-12-06T10:43:35.674197Z","shell.execute_reply.started":"2024-12-06T10:43:35.657845Z","shell.execute_reply":"2024-12-06T10:43:35.673453Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ============================================================================\n# Section 10: Main Training Loop Execution\n# ============================================================================\n\"\"\"\nThis section executes the complete training process, combining all our previous\ncomponents. The main training loop:\n1. Runs for multiple epochs\n2. Tracks and saves the best model\n3. Handles early stopping if needed\n4. Logs comprehensive metrics and progress\n\nWe maintain careful error handling and provide detailed progress updates to\nensure training transparency and reproducibility.\n\"\"\"\n\ndef train_model():\n    \"\"\"\n    Executes the complete training pipeline for our DistilBERT model.\n    \n    This function orchestrates the entire training process, including:\n    - Multiple epoch iterations\n    - Model checkpointing\n    - Performance tracking\n    - Error handling\n    - Progress reporting\n    \n    The training follows best practices for deep learning model training\n    and includes safeguards against common training issues.\n    \"\"\"\n    # Initialize best metric tracking\n    best_eval_loss = float('inf')\n    best_accuracy = 0\n    patience_counter = 0\n    \n    # Create directory for saving model checkpoints\n    os.makedirs('model_checkpoints', exist_ok=True)\n    \n    try:\n        print(\"Starting training process...\")\n        print(f\"Training on device: {device}\")\n        print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n        \n        # Main epoch loop\n        for epoch in range(train_config['epochs']):\n            print(f\"\\n{'='*50}\")\n            print(f\"Epoch {epoch + 1}/{train_config['epochs']}\")\n            print(f\"{'='*50}\")\n            \n            # Training phase\n            epoch_loss = train_epoch(\n                model=model,\n                train_loader=train_loader,\n                optimizer=optimizer,\n                scheduler=scheduler,\n                epoch=epoch\n            )\n            \n            # Evaluation phase\n            print(\"\\nRunning evaluation...\")\n            eval_metrics = evaluate(model, test_loader)\n            \n            # Log all metrics\n            wandb.log({\n                'epoch': epoch + 1,\n                'train_loss': epoch_loss,\n                **eval_metrics\n            })\n            \n            # Print metrics\n            print(f\"\\nEpoch {epoch + 1} Results:\")\n            print(f\"Training Loss: {epoch_loss:.4f}\")\n            print(f\"Evaluation Loss: {eval_metrics['eval_loss']:.4f}\")\n            print(f\"Accuracy: {eval_metrics['accuracy']:.4f}\")\n            print(f\"F1 Score: {eval_metrics['f1']:.4f}\")\n            \n            # Save best model\n            if eval_metrics['accuracy'] > best_accuracy:\n                best_accuracy = eval_metrics['accuracy']\n                print(\"\\nSaving best model...\")\n                \n                # Save model checkpoint\n                checkpoint = {\n                    'epoch': epoch + 1,\n                    'model_state_dict': model.state_dict(),\n                    'optimizer_state_dict': optimizer.state_dict(),\n                    'loss': epoch_loss,\n                    'eval_metrics': eval_metrics\n                }\n                \n                torch.save(\n                    checkpoint,\n                    f'model_checkpoints/best_model_acc_{best_accuracy:.4f}.pt'\n                )\n                \n                # Reset patience counter\n                patience_counter = 0\n            else:\n                patience_counter += 1\n            \n            # Early stopping check\n            if patience_counter >= 3:  # 3 epochs without improvement\n                print(\"\\nEarly stopping triggered - No improvement in accuracy\")\n                break\n                \n    except Exception as e:\n        print(f\"\\nError during training: {str(e)}\")\n        # Log error to WandB\n        wandb.log({\"error\": str(e)})\n        raise e\n    \n    finally:\n        # Always close WandB run properly\n        wandb.finish()\n        \n    return best_accuracy, eval_metrics","metadata":{"_uuid":"aa834714-5955-4c92-b06a-858c7c0480bf","_cell_guid":"9ee74e29-915d-4b89-a6cd-3fdebaba8d22","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:43:35.675265Z","iopub.execute_input":"2024-12-06T10:43:35.675626Z","iopub.status.idle":"2024-12-06T10:43:35.689985Z","shell.execute_reply.started":"2024-12-06T10:43:35.675585Z","shell.execute_reply":"2024-12-06T10:43:35.689147Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ============================================================================\n# Section 11: Model Training Execution and Results Analysis\n# ============================================================================\n\"\"\"\nThis section executes the training process and provides a comprehensive\nanalysis of the results. We collect and present:\n1. Final model performance metrics\n2. Training time analysis\n3. Resource utilization statistics\n4. Error analysis and insights\n\"\"\"\n\nif __name__ == \"__main__\":\n    # Record start time for training duration calculation\n    start_time = time.time()\n    \n    try:\n        print(\"Initiating DistilBERT training for AG News classification...\")\n        \n        # Execute training\n        best_accuracy, final_metrics = train_model()\n        \n        # Calculate training duration\n        training_duration = time.time() - start_time\n        \n        # Print comprehensive results\n        print(\"\\n\" + \"=\"*50)\n        print(\"Training Completed Successfully!\")\n        print(\"=\"*50)\n        print(f\"\\nTotal Training Time: {training_duration/60:.2f} minutes\")\n        print(\"\\nFinal Model Performance:\")\n        print(f\"Best Accuracy: {best_accuracy:.4f}\")\n        print(f\"Final F1 Score: {final_metrics['f1']:.4f}\")\n        print(f\"Final Precision: {final_metrics['precision']:.4f}\")\n        print(f\"Final Recall: {final_metrics['recall']:.4f}\")\n        \n        # Log final results to a file\n        with open('training_results.txt', 'w') as f:\n            f.write(f\"Training Duration: {training_duration/60:.2f} minutes\\n\")\n            f.write(f\"Best Accuracy: {best_accuracy:.4f}\\n\")\n            f.write(f\"Final F1 Score: {final_metrics['f1']:.4f}\\n\")\n            for metric, value in final_metrics.items():\n                f.write(f\"{metric}: {value}\\n\")\n        \n    except Exception as e:\n        print(f\"\\nTraining failed with error: {str(e)}\")\n        # Log error to file\n        with open('training_error_log.txt', 'w') as f:\n            f.write(f\"Error during training: {str(e)}\\n\")","metadata":{"_uuid":"1f794bf4-4b35-4829-ac5f-b92766804e99","_cell_guid":"9be717e6-256c-4865-9f67-89ab60e000d8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T10:43:35.691135Z","iopub.execute_input":"2024-12-06T10:43:35.691415Z","iopub.status.idle":"2024-12-06T12:00:47.434774Z","shell.execute_reply.started":"2024-12-06T10:43:35.691372Z","shell.execute_reply":"2024-12-06T12:00:47.433886Z"}},"outputs":[{"name":"stdout","text":"Initiating DistilBERT training for AG News classification...\nStarting training process...\nTraining on device: cuda\nNumber of GPUs: 2\n\n==================================================\nEpoch 1/5\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:   0%|          | 0/3750 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nEpoch 1 - Loss: 0.2678: 100%|██████████| 3750/3750 [14:51<00:00,  4.20it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nRunning evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   1%|          | 2/238 [00:00<00:18, 13.07it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   2%|▏         | 4/238 [00:00<00:18, 12.64it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 6/238 [00:00<00:18, 12.62it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 8/238 [00:00<00:18, 12.57it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   4%|▍         | 10/238 [00:00<00:18, 12.55it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   5%|▌         | 12/238 [00:00<00:17, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   6%|▌         | 14/238 [00:01<00:17, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   7%|▋         | 16/238 [00:01<00:17, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 18/238 [00:01<00:17, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 20/238 [00:01<00:17, 12.58it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   9%|▉         | 22/238 [00:01<00:17, 12.54it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  10%|█         | 24/238 [00:01<00:16, 12.67it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  11%|█         | 26/238 [00:02<00:16, 12.68it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  12%|█▏        | 28/238 [00:02<00:16, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 30/238 [00:02<00:16, 12.60it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 32/238 [00:02<00:16, 12.53it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  14%|█▍        | 34/238 [00:02<00:16, 12.47it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  15%|█▌        | 36/238 [00:02<00:16, 12.47it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  16%|█▌        | 38/238 [00:03<00:16, 12.50it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  17%|█▋        | 40/238 [00:03<00:15, 12.58it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 42/238 [00:03<00:15, 12.68it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 44/238 [00:03<00:15, 12.66it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  19%|█▉        | 46/238 [00:03<00:15, 12.59it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  20%|██        | 48/238 [00:03<00:15, 12.56it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  21%|██        | 50/238 [00:03<00:14, 12.59it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  22%|██▏       | 52/238 [00:04<00:14, 12.68it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  23%|██▎       | 54/238 [00:04<00:14, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▎       | 56/238 [00:04<00:14, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▍       | 58/238 [00:04<00:14, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  25%|██▌       | 60/238 [00:04<00:13, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  26%|██▌       | 62/238 [00:04<00:13, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  27%|██▋       | 64/238 [00:05<00:13, 12.71it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  28%|██▊       | 66/238 [00:05<00:13, 12.66it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▊       | 68/238 [00:05<00:13, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▉       | 70/238 [00:05<00:13, 12.71it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  30%|███       | 72/238 [00:05<00:13, 12.71it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  31%|███       | 74/238 [00:05<00:13, 12.61it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  32%|███▏      | 76/238 [00:06<00:12, 12.58it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  33%|███▎      | 78/238 [00:06<00:12, 12.61it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▎      | 80/238 [00:06<00:12, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▍      | 82/238 [00:06<00:12, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  35%|███▌      | 84/238 [00:06<00:12, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  36%|███▌      | 86/238 [00:06<00:11, 12.71it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  37%|███▋      | 88/238 [00:06<00:11, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  38%|███▊      | 90/238 [00:07<00:11, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▊      | 92/238 [00:07<00:11, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▉      | 94/238 [00:07<00:11, 12.67it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  40%|████      | 96/238 [00:07<00:11, 12.74it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  41%|████      | 98/238 [00:07<00:10, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  42%|████▏     | 100/238 [00:07<00:10, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  43%|████▎     | 102/238 [00:08<00:10, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  44%|████▎     | 104/238 [00:08<00:10, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▍     | 106/238 [00:08<00:10, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▌     | 108/238 [00:08<00:10, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  46%|████▌     | 110/238 [00:08<00:10, 12.66it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  47%|████▋     | 112/238 [00:08<00:09, 12.66it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  48%|████▊     | 114/238 [00:08<00:09, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  49%|████▊     | 116/238 [00:09<00:09, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|████▉     | 118/238 [00:09<00:09, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|█████     | 120/238 [00:09<00:09, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  51%|█████▏    | 122/238 [00:09<00:09, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  52%|█████▏    | 124/238 [00:09<00:08, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  53%|█████▎    | 126/238 [00:09<00:08, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  54%|█████▍    | 128/238 [00:10<00:08, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▍    | 130/238 [00:10<00:08, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▌    | 132/238 [00:10<00:08, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  56%|█████▋    | 134/238 [00:10<00:08, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  57%|█████▋    | 136/238 [00:10<00:08, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  58%|█████▊    | 138/238 [00:10<00:07, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  59%|█████▉    | 140/238 [00:11<00:07, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  60%|█████▉    | 142/238 [00:11<00:07, 12.74it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████    | 144/238 [00:11<00:07, 12.64it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████▏   | 146/238 [00:11<00:07, 12.57it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  62%|██████▏   | 148/238 [00:11<00:07, 12.57it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  63%|██████▎   | 150/238 [00:11<00:06, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  64%|██████▍   | 152/238 [00:11<00:06, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  65%|██████▍   | 154/238 [00:12<00:06, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▋   | 158/238 [00:12<00:08,  9.40it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  67%|██████▋   | 160/238 [00:12<00:07, 10.20it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  69%|██████▉   | 164/238 [00:13<00:06, 11.40it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  70%|██████▉   | 166/238 [00:13<00:06, 11.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████▏  | 170/238 [00:13<00:05, 12.17it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  72%|███████▏  | 172/238 [00:13<00:05, 12.39it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  74%|███████▍  | 176/238 [00:14<00:04, 12.52it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  75%|███████▍  | 178/238 [00:14<00:04, 12.60it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▋  | 182/238 [00:14<00:04, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  77%|███████▋  | 184/238 [00:14<00:04, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  79%|███████▉  | 188/238 [00:15<00:03, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  80%|███████▉  | 190/238 [00:15<00:03, 12.74it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 194/238 [00:15<00:03, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 196/238 [00:15<00:03, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  84%|████████▍ | 200/238 [00:16<00:02, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  85%|████████▍ | 202/238 [00:16<00:02, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 206/238 [00:16<00:02, 12.71it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 208/238 [00:16<00:02, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  89%|████████▉ | 212/238 [00:16<00:02, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  90%|████████▉ | 214/238 [00:17<00:01, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 218/238 [00:17<00:01, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 220/238 [00:17<00:01, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  94%|█████████▍| 224/238 [00:17<00:01, 12.64it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  95%|█████████▍| 226/238 [00:18<00:00, 12.66it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 230/238 [00:18<00:00, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 232/238 [00:18<00:00, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  99%|█████████▉| 236/238 [00:18<00:00, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 238/238 [00:18<00:00, 12.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([16, 4]), Labels shape: torch.Size([16])\n\nEpoch 1 Results:\nTraining Loss: 0.2678\nEvaluation Loss: 0.1768\nAccuracy: 0.9417\nF1 Score: 0.9417\n\nSaving best model...\n\n==================================================\nEpoch 2/5\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:   0%|          | 0/3750 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nEpoch 2 - Loss: 0.1401: 100%|██████████| 3750/3750 [15:11<00:00,  4.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nRunning evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   1%|          | 2/238 [00:00<00:16, 13.94it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   2%|▏         | 4/238 [00:00<00:17, 13.36it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 6/238 [00:00<00:17, 13.03it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 8/238 [00:00<00:17, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   4%|▍         | 10/238 [00:00<00:17, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   5%|▌         | 12/238 [00:00<00:17, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   6%|▌         | 14/238 [00:01<00:17, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   7%|▋         | 16/238 [00:01<00:17, 12.94it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 18/238 [00:01<00:17, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 20/238 [00:01<00:16, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   9%|▉         | 22/238 [00:01<00:16, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  10%|█         | 24/238 [00:01<00:16, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  11%|█         | 26/238 [00:02<00:16, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  12%|█▏        | 28/238 [00:02<00:16, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 30/238 [00:02<00:16, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 32/238 [00:02<00:15, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  14%|█▍        | 34/238 [00:02<00:15, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  15%|█▌        | 36/238 [00:02<00:15, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  16%|█▌        | 38/238 [00:02<00:15, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  17%|█▋        | 40/238 [00:03<00:15, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 42/238 [00:03<00:15, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 44/238 [00:03<00:15, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  19%|█▉        | 46/238 [00:03<00:14, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  20%|██        | 48/238 [00:03<00:14, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  21%|██        | 50/238 [00:03<00:14, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  22%|██▏       | 52/238 [00:04<00:14, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  23%|██▎       | 54/238 [00:04<00:14, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▎       | 56/238 [00:04<00:14, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▍       | 58/238 [00:04<00:13, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  25%|██▌       | 60/238 [00:04<00:13, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  26%|██▌       | 62/238 [00:04<00:13, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  27%|██▋       | 64/238 [00:04<00:13, 12.94it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  28%|██▊       | 66/238 [00:05<00:13, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▊       | 68/238 [00:05<00:13, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▉       | 70/238 [00:05<00:13, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  30%|███       | 72/238 [00:05<00:12, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  31%|███       | 74/238 [00:05<00:12, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  32%|███▏      | 76/238 [00:05<00:12, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  33%|███▎      | 78/238 [00:06<00:12, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▎      | 80/238 [00:06<00:12, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▍      | 82/238 [00:06<00:12, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  35%|███▌      | 84/238 [00:06<00:11, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  36%|███▌      | 86/238 [00:06<00:11, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  37%|███▋      | 88/238 [00:06<00:11, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  38%|███▊      | 90/238 [00:06<00:11, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▊      | 92/238 [00:07<00:11, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▉      | 94/238 [00:07<00:11, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  40%|████      | 96/238 [00:07<00:11, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  41%|████      | 98/238 [00:07<00:10, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  42%|████▏     | 100/238 [00:07<00:10, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  43%|████▎     | 102/238 [00:07<00:10, 12.95it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  44%|████▎     | 104/238 [00:08<00:10, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▍     | 106/238 [00:08<00:10, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▌     | 108/238 [00:08<00:10, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  46%|████▌     | 110/238 [00:08<00:09, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  47%|████▋     | 112/238 [00:08<00:09, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  48%|████▊     | 114/238 [00:08<00:09, 12.94it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  49%|████▊     | 116/238 [00:09<00:09, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|████▉     | 118/238 [00:09<00:09, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|█████     | 120/238 [00:09<00:09, 12.93it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  51%|█████▏    | 122/238 [00:09<00:09, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  52%|█████▏    | 124/238 [00:09<00:08, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  53%|█████▎    | 126/238 [00:09<00:08, 12.95it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  54%|█████▍    | 128/238 [00:09<00:08, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▍    | 130/238 [00:10<00:08, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▌    | 132/238 [00:10<00:08, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  56%|█████▋    | 134/238 [00:10<00:08, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  57%|█████▋    | 136/238 [00:10<00:07, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  58%|█████▊    | 138/238 [00:10<00:07, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  59%|█████▉    | 140/238 [00:10<00:07, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  60%|█████▉    | 142/238 [00:11<00:07, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████    | 144/238 [00:11<00:07, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████▏   | 146/238 [00:11<00:07, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  62%|██████▏   | 148/238 [00:11<00:06, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  63%|██████▎   | 150/238 [00:11<00:06, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  64%|██████▍   | 152/238 [00:11<00:06, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  65%|██████▍   | 154/238 [00:11<00:06, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▌   | 156/238 [00:12<00:06, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▋   | 158/238 [00:12<00:06, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  67%|██████▋   | 160/238 [00:12<00:06, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  68%|██████▊   | 162/238 [00:12<00:05, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  69%|██████▉   | 164/238 [00:12<00:05, 12.97it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  70%|██████▉   | 166/238 [00:12<00:05, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████   | 168/238 [00:13<00:05, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████▏  | 170/238 [00:13<00:05, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  72%|███████▏  | 172/238 [00:13<00:05, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  73%|███████▎  | 174/238 [00:13<00:04, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  74%|███████▍  | 176/238 [00:13<00:04, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  75%|███████▍  | 178/238 [00:13<00:04, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▌  | 180/238 [00:13<00:04, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▋  | 182/238 [00:14<00:04, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  77%|███████▋  | 184/238 [00:14<00:04, 12.93it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  78%|███████▊  | 186/238 [00:14<00:04, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  79%|███████▉  | 188/238 [00:14<00:03, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  80%|███████▉  | 190/238 [00:14<00:03, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  81%|████████  | 192/238 [00:14<00:03, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 194/238 [00:15<00:03, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 196/238 [00:15<00:03, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  83%|████████▎ | 198/238 [00:15<00:03, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  84%|████████▍ | 200/238 [00:15<00:02, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  85%|████████▍ | 202/238 [00:15<00:02, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  86%|████████▌ | 204/238 [00:15<00:02, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 206/238 [00:16<00:02, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 208/238 [00:16<00:02, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  88%|████████▊ | 210/238 [00:16<00:02, 12.95it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  89%|████████▉ | 212/238 [00:16<00:02, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  90%|████████▉ | 214/238 [00:16<00:01, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  91%|█████████ | 216/238 [00:16<00:01, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 218/238 [00:16<00:01, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 220/238 [00:17<00:01, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  93%|█████████▎| 222/238 [00:17<00:01, 12.93it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  94%|█████████▍| 224/238 [00:17<00:01, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  95%|█████████▍| 226/238 [00:17<00:00, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  96%|█████████▌| 228/238 [00:17<00:00, 12.95it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 230/238 [00:17<00:00, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 232/238 [00:18<00:00, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  98%|█████████▊| 234/238 [00:18<00:00, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  99%|█████████▉| 236/238 [00:18<00:00, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 238/238 [00:18<00:00, 12.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([16, 4]), Labels shape: torch.Size([16])\n\nEpoch 2 Results:\nTraining Loss: 0.1401\nEvaluation Loss: 0.1695\nAccuracy: 0.9436\nF1 Score: 0.9436\n\nSaving best model...\n\n==================================================\nEpoch 3/5\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:   0%|          | 0/3750 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nEpoch 3 - Loss: 0.0970: 100%|██████████| 3750/3750 [15:09<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nRunning evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   1%|          | 2/238 [00:00<00:17, 13.63it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   2%|▏         | 4/238 [00:00<00:17, 13.25it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 6/238 [00:00<00:17, 13.05it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 8/238 [00:00<00:17, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   4%|▍         | 10/238 [00:00<00:17, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   5%|▌         | 12/238 [00:00<00:17, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   6%|▌         | 14/238 [00:01<00:17, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   7%|▋         | 16/238 [00:01<00:17, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 18/238 [00:01<00:17, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 20/238 [00:01<00:16, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   9%|▉         | 22/238 [00:01<00:16, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  10%|█         | 24/238 [00:01<00:16, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  11%|█         | 26/238 [00:02<00:16, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  12%|█▏        | 28/238 [00:02<00:16, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 30/238 [00:02<00:16, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 32/238 [00:02<00:16, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  14%|█▍        | 34/238 [00:02<00:15, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  15%|█▌        | 36/238 [00:02<00:15, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  16%|█▌        | 38/238 [00:02<00:15, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  17%|█▋        | 40/238 [00:03<00:15, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 42/238 [00:03<00:15, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 44/238 [00:03<00:15, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  19%|█▉        | 46/238 [00:03<00:14, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  20%|██        | 48/238 [00:03<00:14, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  21%|██        | 50/238 [00:03<00:14, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  22%|██▏       | 52/238 [00:04<00:14, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  23%|██▎       | 54/238 [00:04<00:14, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▎       | 56/238 [00:04<00:14, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▍       | 58/238 [00:04<00:14, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  25%|██▌       | 60/238 [00:04<00:13, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  26%|██▌       | 62/238 [00:04<00:13, 12.93it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  27%|██▋       | 64/238 [00:04<00:13, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  28%|██▊       | 66/238 [00:05<00:13, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▊       | 68/238 [00:05<00:13, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▉       | 70/238 [00:05<00:13, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  30%|███       | 72/238 [00:05<00:12, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  31%|███       | 74/238 [00:05<00:12, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  32%|███▏      | 76/238 [00:05<00:12, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  33%|███▎      | 78/238 [00:06<00:12, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▎      | 80/238 [00:06<00:12, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▍      | 82/238 [00:06<00:12, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  35%|███▌      | 84/238 [00:06<00:12, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  36%|███▌      | 86/238 [00:06<00:11, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  37%|███▋      | 88/238 [00:06<00:11, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  38%|███▊      | 90/238 [00:07<00:11, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▊      | 92/238 [00:07<00:11, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▉      | 94/238 [00:07<00:11, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  40%|████      | 96/238 [00:07<00:11, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  41%|████      | 98/238 [00:07<00:10, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  42%|████▏     | 100/238 [00:07<00:10, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  43%|████▎     | 102/238 [00:07<00:10, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  44%|████▎     | 104/238 [00:08<00:10, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▍     | 106/238 [00:08<00:10, 12.93it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▌     | 108/238 [00:08<00:10, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  46%|████▌     | 110/238 [00:08<00:09, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  47%|████▋     | 112/238 [00:08<00:09, 12.94it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  48%|████▊     | 114/238 [00:08<00:09, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  49%|████▊     | 116/238 [00:09<00:09, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|████▉     | 118/238 [00:09<00:09, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|█████     | 120/238 [00:09<00:09, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  51%|█████▏    | 122/238 [00:09<00:09, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  52%|█████▏    | 124/238 [00:09<00:08, 12.67it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  53%|█████▎    | 126/238 [00:09<00:08, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  54%|█████▍    | 128/238 [00:09<00:08, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▍    | 130/238 [00:10<00:08, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▌    | 132/238 [00:10<00:08, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  56%|█████▋    | 134/238 [00:10<00:08, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  57%|█████▋    | 136/238 [00:10<00:07, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  58%|█████▊    | 138/238 [00:10<00:07, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  59%|█████▉    | 140/238 [00:10<00:07, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  60%|█████▉    | 142/238 [00:11<00:07, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████    | 144/238 [00:11<00:07, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████▏   | 146/238 [00:11<00:07, 12.93it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  62%|██████▏   | 148/238 [00:11<00:07, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  63%|██████▎   | 150/238 [00:11<00:06, 12.93it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  64%|██████▍   | 152/238 [00:11<00:06, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  65%|██████▍   | 154/238 [00:11<00:06, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▌   | 156/238 [00:12<00:09,  8.27it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  67%|██████▋   | 160/238 [00:12<00:07, 10.14it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  68%|██████▊   | 162/238 [00:12<00:07, 10.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  70%|██████▉   | 166/238 [00:13<00:06, 11.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████   | 168/238 [00:13<00:05, 12.15it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  72%|███████▏  | 172/238 [00:13<00:05, 12.46it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  73%|███████▎  | 174/238 [00:13<00:05, 12.60it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  75%|███████▍  | 178/238 [00:14<00:04, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▌  | 180/238 [00:14<00:04, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  77%|███████▋  | 184/238 [00:14<00:04, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  78%|███████▊  | 186/238 [00:14<00:04, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  80%|███████▉  | 190/238 [00:15<00:03, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  81%|████████  | 192/238 [00:15<00:03, 12.95it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 196/238 [00:15<00:03, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  83%|████████▎ | 198/238 [00:15<00:03, 12.98it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  85%|████████▍ | 202/238 [00:15<00:02, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  86%|████████▌ | 204/238 [00:16<00:02, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 208/238 [00:16<00:02, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  88%|████████▊ | 210/238 [00:16<00:02, 12.93it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  90%|████████▉ | 214/238 [00:16<00:01, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  91%|█████████ | 216/238 [00:17<00:01, 12.93it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 220/238 [00:17<00:01, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  93%|█████████▎| 222/238 [00:17<00:01, 12.97it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  95%|█████████▍| 226/238 [00:17<00:00, 12.96it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  96%|█████████▌| 228/238 [00:18<00:00, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 232/238 [00:18<00:00, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  98%|█████████▊| 234/238 [00:18<00:00, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 238/238 [00:18<00:00, 12.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([16, 4]), Labels shape: torch.Size([16])\n\nEpoch 3 Results:\nTraining Loss: 0.0970\nEvaluation Loss: 0.1967\nAccuracy: 0.9429\nF1 Score: 0.9429\n\n==================================================\nEpoch 4/5\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:   0%|          | 0/3750 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nEpoch 4 - Loss: 0.0668: 100%|██████████| 3750/3750 [15:09<00:00,  4.12it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nRunning evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   1%|          | 2/238 [00:00<00:17, 13.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   2%|▏         | 4/238 [00:00<00:17, 13.29it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 6/238 [00:00<00:17, 12.94it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 8/238 [00:00<00:17, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   4%|▍         | 10/238 [00:00<00:17, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   5%|▌         | 12/238 [00:00<00:17, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   6%|▌         | 14/238 [00:01<00:17, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   7%|▋         | 16/238 [00:01<00:17, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 18/238 [00:01<00:17, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 20/238 [00:01<00:16, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   9%|▉         | 22/238 [00:01<00:16, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  10%|█         | 24/238 [00:01<00:16, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  11%|█         | 26/238 [00:02<00:16, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  12%|█▏        | 28/238 [00:02<00:16, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 30/238 [00:02<00:16, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 32/238 [00:02<00:15, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  14%|█▍        | 34/238 [00:02<00:15, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  15%|█▌        | 36/238 [00:02<00:15, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  16%|█▌        | 38/238 [00:02<00:15, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  17%|█▋        | 40/238 [00:03<00:15, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 42/238 [00:03<00:15, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 44/238 [00:03<00:15, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  19%|█▉        | 46/238 [00:03<00:14, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  20%|██        | 48/238 [00:03<00:14, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  21%|██        | 50/238 [00:03<00:14, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  22%|██▏       | 52/238 [00:04<00:14, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  23%|██▎       | 54/238 [00:04<00:14, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▎       | 56/238 [00:04<00:14, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▍       | 58/238 [00:04<00:13, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  25%|██▌       | 60/238 [00:04<00:13, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  26%|██▌       | 62/238 [00:04<00:13, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  27%|██▋       | 64/238 [00:04<00:13, 12.92it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  28%|██▊       | 66/238 [00:05<00:13, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▊       | 68/238 [00:05<00:13, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▉       | 70/238 [00:05<00:13, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  30%|███       | 72/238 [00:05<00:12, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  31%|███       | 74/238 [00:05<00:12, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  32%|███▏      | 76/238 [00:05<00:12, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  33%|███▎      | 78/238 [00:06<00:12, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▎      | 80/238 [00:06<00:12, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▍      | 82/238 [00:06<00:12, 12.74it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  35%|███▌      | 84/238 [00:06<00:12, 12.71it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  36%|███▌      | 86/238 [00:06<00:11, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  37%|███▋      | 88/238 [00:06<00:11, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  38%|███▊      | 90/238 [00:07<00:11, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▊      | 92/238 [00:07<00:11, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▉      | 94/238 [00:07<00:11, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  40%|████      | 96/238 [00:07<00:11, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  41%|████      | 98/238 [00:07<00:10, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  42%|████▏     | 100/238 [00:07<00:10, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  43%|████▎     | 102/238 [00:07<00:10, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  44%|████▎     | 104/238 [00:08<00:10, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▍     | 106/238 [00:08<00:10, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▌     | 108/238 [00:08<00:10, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  46%|████▌     | 110/238 [00:08<00:09, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  47%|████▋     | 112/238 [00:08<00:09, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  48%|████▊     | 114/238 [00:08<00:09, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  49%|████▊     | 116/238 [00:09<00:09, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|████▉     | 118/238 [00:09<00:09, 12.94it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|█████     | 120/238 [00:09<00:09, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  52%|█████▏    | 124/238 [00:09<00:12,  9.21it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  53%|█████▎    | 126/238 [00:10<00:11, 10.06it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▍    | 130/238 [00:10<00:09, 11.33it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▌    | 132/238 [00:10<00:09, 11.74it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  57%|█████▋    | 136/238 [00:10<00:08, 12.29it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  58%|█████▊    | 138/238 [00:11<00:08, 12.42it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  60%|█████▉    | 142/238 [00:11<00:07, 12.67it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████    | 144/238 [00:11<00:07, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  62%|██████▏   | 148/238 [00:11<00:07, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  63%|██████▎   | 150/238 [00:11<00:06, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  65%|██████▍   | 154/238 [00:12<00:06, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▌   | 156/238 [00:12<00:06, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  67%|██████▋   | 160/238 [00:12<00:06, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  68%|██████▊   | 162/238 [00:12<00:05, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  70%|██████▉   | 166/238 [00:13<00:05, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████   | 168/238 [00:13<00:05, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  72%|███████▏  | 172/238 [00:13<00:05, 12.87it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  73%|███████▎  | 174/238 [00:13<00:04, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  75%|███████▍  | 178/238 [00:14<00:04, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▌  | 180/238 [00:14<00:04, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  77%|███████▋  | 184/238 [00:14<00:04, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  78%|███████▊  | 186/238 [00:14<00:04, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  80%|███████▉  | 190/238 [00:15<00:03, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  81%|████████  | 192/238 [00:15<00:03, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 196/238 [00:15<00:03, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  83%|████████▎ | 198/238 [00:15<00:03, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  85%|████████▍ | 202/238 [00:15<00:02, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  86%|████████▌ | 204/238 [00:16<00:02, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 208/238 [00:16<00:02, 12.91it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  88%|████████▊ | 210/238 [00:16<00:02, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  90%|████████▉ | 214/238 [00:16<00:01, 12.84it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  91%|█████████ | 216/238 [00:17<00:01, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 220/238 [00:17<00:01, 12.94it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  93%|█████████▎| 222/238 [00:17<00:01, 12.86it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  95%|█████████▍| 226/238 [00:17<00:00, 12.90it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  96%|█████████▌| 228/238 [00:18<00:00, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 232/238 [00:18<00:00, 12.89it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  98%|█████████▊| 234/238 [00:18<00:00, 12.82it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 238/238 [00:18<00:00, 12.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([16, 4]), Labels shape: torch.Size([16])\n\nEpoch 4 Results:\nTraining Loss: 0.0668\nEvaluation Loss: 0.2278\nAccuracy: 0.9409\nF1 Score: 0.9409\n\n==================================================\nEpoch 5/5\n==================================================\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:   0%|          | 0/3750 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nEpoch 5 - Loss: 0.0458: 100%|██████████| 3750/3750 [15:08<00:00,  4.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nRunning evaluation...\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   1%|          | 2/238 [00:00<00:17, 13.56it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   2%|▏         | 4/238 [00:00<00:17, 13.10it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 6/238 [00:00<00:17, 13.02it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   3%|▎         | 8/238 [00:00<00:17, 12.88it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   4%|▍         | 10/238 [00:00<00:17, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   5%|▌         | 12/238 [00:00<00:17, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   6%|▌         | 14/238 [00:01<00:17, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   7%|▋         | 16/238 [00:01<00:17, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 18/238 [00:01<00:17, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   8%|▊         | 20/238 [00:01<00:17, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:   9%|▉         | 22/238 [00:01<00:17, 12.61it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  10%|█         | 24/238 [00:01<00:16, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  11%|█         | 26/238 [00:02<00:16, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  12%|█▏        | 28/238 [00:02<00:16, 12.71it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 30/238 [00:02<00:16, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  13%|█▎        | 32/238 [00:02<00:16, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  14%|█▍        | 34/238 [00:02<00:15, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  15%|█▌        | 36/238 [00:02<00:15, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  16%|█▌        | 38/238 [00:02<00:15, 12.71it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  17%|█▋        | 40/238 [00:03<00:15, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 42/238 [00:03<00:15, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  18%|█▊        | 44/238 [00:03<00:15, 12.74it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  19%|█▉        | 46/238 [00:03<00:15, 12.60it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  20%|██        | 48/238 [00:03<00:15, 12.60it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  21%|██        | 50/238 [00:03<00:14, 12.66it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  22%|██▏       | 52/238 [00:04<00:14, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  23%|██▎       | 54/238 [00:04<00:14, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▎       | 56/238 [00:04<00:14, 12.64it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  24%|██▍       | 58/238 [00:04<00:14, 12.59it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  25%|██▌       | 60/238 [00:04<00:14, 12.56it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  26%|██▌       | 62/238 [00:04<00:13, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  27%|██▋       | 64/238 [00:05<00:13, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  28%|██▊       | 66/238 [00:05<00:13, 12.68it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▊       | 68/238 [00:05<00:13, 12.59it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  29%|██▉       | 70/238 [00:05<00:13, 12.51it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  30%|███       | 72/238 [00:05<00:13, 12.54it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  31%|███       | 74/238 [00:05<00:13, 12.61it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  32%|███▏      | 76/238 [00:05<00:12, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  33%|███▎      | 78/238 [00:06<00:12, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▎      | 80/238 [00:06<00:12, 12.62it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  34%|███▍      | 82/238 [00:06<00:12, 12.59it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  35%|███▌      | 84/238 [00:06<00:12, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  36%|███▌      | 86/238 [00:06<00:11, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  37%|███▋      | 88/238 [00:06<00:11, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  38%|███▊      | 90/238 [00:07<00:11, 12.67it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▊      | 92/238 [00:07<00:11, 12.68it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  39%|███▉      | 94/238 [00:07<00:11, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  40%|████      | 96/238 [00:07<00:11, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  41%|████      | 98/238 [00:07<00:11, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  42%|████▏     | 100/238 [00:07<00:10, 12.63it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  43%|████▎     | 102/238 [00:08<00:10, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  44%|████▎     | 104/238 [00:08<00:10, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▍     | 106/238 [00:08<00:10, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  45%|████▌     | 108/238 [00:08<00:10, 12.66it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  46%|████▌     | 110/238 [00:08<00:10, 12.61it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  47%|████▋     | 112/238 [00:08<00:10, 12.57it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  48%|████▊     | 114/238 [00:08<00:09, 12.60it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  49%|████▊     | 116/238 [00:09<00:09, 12.68it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|████▉     | 118/238 [00:09<00:09, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  50%|█████     | 120/238 [00:09<00:09, 12.66it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  51%|█████▏    | 122/238 [00:09<00:09, 12.64it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  52%|█████▏    | 124/238 [00:09<00:08, 12.74it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  53%|█████▎    | 126/238 [00:09<00:08, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  54%|█████▍    | 128/238 [00:10<00:08, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▍    | 130/238 [00:10<00:08, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  55%|█████▌    | 132/238 [00:10<00:08, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  56%|█████▋    | 134/238 [00:10<00:08, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  57%|█████▋    | 136/238 [00:10<00:07, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  58%|█████▊    | 138/238 [00:10<00:07, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  59%|█████▉    | 140/238 [00:11<00:07, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  60%|█████▉    | 142/238 [00:11<00:07, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████    | 144/238 [00:11<00:07, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  61%|██████▏   | 146/238 [00:11<00:07, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  62%|██████▏   | 148/238 [00:11<00:07, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  63%|██████▎   | 150/238 [00:11<00:06, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  64%|██████▍   | 152/238 [00:11<00:06, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  65%|██████▍   | 154/238 [00:12<00:06, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▌   | 156/238 [00:12<00:06, 12.85it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  66%|██████▋   | 158/238 [00:12<00:06, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  67%|██████▋   | 160/238 [00:12<00:06, 12.71it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  68%|██████▊   | 162/238 [00:12<00:05, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  69%|██████▉   | 164/238 [00:12<00:05, 12.81it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  70%|██████▉   | 166/238 [00:13<00:05, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████   | 168/238 [00:13<00:05, 12.68it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  71%|███████▏  | 170/238 [00:13<00:05, 12.64it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  72%|███████▏  | 172/238 [00:13<00:05, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  73%|███████▎  | 174/238 [00:13<00:05, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  74%|███████▍  | 176/238 [00:13<00:04, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  75%|███████▍  | 178/238 [00:14<00:04, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▌  | 180/238 [00:14<00:04, 12.68it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  76%|███████▋  | 182/238 [00:14<00:04, 12.74it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  77%|███████▋  | 184/238 [00:14<00:04, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  78%|███████▊  | 186/238 [00:14<00:04, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  79%|███████▉  | 188/238 [00:14<00:03, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  80%|███████▉  | 190/238 [00:14<00:03, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  81%|████████  | 192/238 [00:15<00:03, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 194/238 [00:15<00:03, 12.74it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  82%|████████▏ | 196/238 [00:15<00:03, 12.73it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  83%|████████▎ | 198/238 [00:15<00:03, 12.69it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  84%|████████▍ | 200/238 [00:15<00:02, 12.77it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  85%|████████▍ | 202/238 [00:15<00:02, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  86%|████████▌ | 204/238 [00:16<00:02, 12.71it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 206/238 [00:16<00:02, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  87%|████████▋ | 208/238 [00:16<00:02, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  88%|████████▊ | 210/238 [00:16<00:02, 12.83it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  89%|████████▉ | 212/238 [00:16<00:02, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  90%|████████▉ | 214/238 [00:16<00:01, 12.68it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  91%|█████████ | 216/238 [00:16<00:01, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 218/238 [00:17<00:01, 12.78it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  92%|█████████▏| 220/238 [00:17<00:01, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  93%|█████████▎| 222/238 [00:17<00:01, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  94%|█████████▍| 224/238 [00:17<00:01, 12.65it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  95%|█████████▍| 226/238 [00:17<00:00, 12.76it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  96%|█████████▌| 228/238 [00:17<00:00, 12.79it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 230/238 [00:18<00:00, 12.72it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  97%|█████████▋| 232/238 [00:18<00:00, 12.70it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  98%|█████████▊| 234/238 [00:18<00:00, 12.80it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating:  99%|█████████▉| 236/238 [00:18<00:00, 12.75it/s]","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\nLogits shape: torch.Size([32, 4]), Labels shape: torch.Size([32])\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 238/238 [00:18<00:00, 12.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Logits shape: torch.Size([16, 4]), Labels shape: torch.Size([16])\n\nEpoch 5 Results:\nTraining Loss: 0.0458\nEvaluation Loss: 0.2634\nAccuracy: 0.9420\nF1 Score: 0.9420\n\nEarly stopping triggered - No improvement in accuracy\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <style>\n        .wandb-row {\n            display: flex;\n            flex-direction: row;\n            flex-wrap: wrap;\n            justify-content: flex-start;\n            width: 100%;\n        }\n        .wandb-col {\n            display: flex;\n            flex-direction: column;\n            flex-basis: 100%;\n            flex: 1;\n            padding: 10px;\n        }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▃█▆▁▄</td></tr><tr><td>average_loss</td><td>██▆▃▃▂▂▁▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>batch_loss</td><td>█▄▂▂▂▂▂▃▂▂▂▁▂▁▁▃▃▁▂▂▁▂▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▄▄▄▄▄▄▅▅▅▅▅▅▅▅▅▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>eval_loss</td><td>▂▁▃▅█</td></tr><tr><td>f1</td><td>▃█▆▁▄</td></tr><tr><td>learning_rate</td><td>▁▂██▇▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▁</td></tr><tr><td>precision</td><td>▃██▁▄</td></tr><tr><td>recall</td><td>▃█▆▁▄</td></tr><tr><td>step</td><td>▂▂▃▄▅▆▆▇▇▁▃▄▅▅▆▇▇▇█▃▅▅▆█▂▂▄▄▅▆▆▆▇▇▁▂▃▄▆█</td></tr><tr><td>train_loss</td><td>█▄▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.94197</td></tr><tr><td>average_loss</td><td>0.0457</td></tr><tr><td>batch_loss</td><td>0.01611</td></tr><tr><td>epoch</td><td>5</td></tr><tr><td>eval_loss</td><td>0.26343</td></tr><tr><td>f1</td><td>0.94201</td></tr><tr><td>learning_rate</td><td>0.0</td></tr><tr><td>precision</td><td>0.94209</td></tr><tr><td>recall</td><td>0.94197</td></tr><tr><td>step</td><td>3700</td></tr><tr><td>train_loss</td><td>0.04584</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">distilbert-baseline</strong> at: <a href='https://wandb.ai/shivayshakti2025-nasa/ag-news-classification/runs/3mlf6inp' target=\"_blank\">https://wandb.ai/shivayshakti2025-nasa/ag-news-classification/runs/3mlf6inp</a><br/> View project at: <a href='https://wandb.ai/shivayshakti2025-nasa/ag-news-classification' target=\"_blank\">https://wandb.ai/shivayshakti2025-nasa/ag-news-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20241206_104334-3mlf6inp/logs</code>"},"metadata":{}},{"name":"stdout","text":"\n==================================================\nTraining Completed Successfully!\n==================================================\n\nTotal Training Time: 77.20 minutes\n\nFinal Model Performance:\nBest Accuracy: 0.9436\nFinal F1 Score: 0.9420\nFinal Precision: 0.9421\nFinal Recall: 0.9420\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ============================================================================\n# Section 12: Model Analysis and Performance Reporting\n# ============================================================================\n\"\"\"\nThis section provides detailed analysis of the trained model's performance,\nincluding inference time measurements, resource utilization patterns, and\ncomprehensive benchmarking across different scenarios. This information is\ncrucial for both research documentation and practical deployment decisions.\n\"\"\"\n\ndef analyze_model_performance():\n    \"\"\"\n    Conducts comprehensive performance analysis of the trained model,\n    measuring inference speeds, resource usage, and scalability characteristics.\n    This provides crucial data for both academic reporting and practical deployment.\n    \"\"\"\n    # Load the best model checkpoint\n    best_model_path = max(glob.glob('model_checkpoints/best_model_*.pt'), key=os.path.getctime)\n    checkpoint = torch.load(best_model_path)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.eval()\n\n    # Prepare test scenarios\n    test_scenarios = {\n        'single_sample': [test_dataset[0]],\n        'small_batch': [test_dataset[i] for i in range(16)],\n        'medium_batch': [test_dataset[i] for i in range(32)],\n        'large_batch': [test_dataset[i] for i in range(64)]\n    }\n\n    performance_metrics = {}\n    \n    for scenario_name, samples in test_scenarios.items():\n        # Measure inference time\n        latencies = []\n        memory_usage = []\n        \n        # Warm-up runs\n        for _ in range(5):\n            _ = predict_batch(model, samples)\n        \n        # Actual measurements\n        for _ in range(20):\n            torch.cuda.reset_peak_memory_stats()\n            start_time = time.time()\n            \n            _ = predict_batch(model, samples)\n            \n            latencies.append(time.time() - start_time)\n            memory_usage.append(torch.cuda.max_memory_allocated())\n        \n        performance_metrics[scenario_name] = {\n            'avg_latency': np.mean(latencies),\n            'p95_latency': np.percentile(latencies, 95),\n            'avg_memory': np.mean(memory_usage) / (1024**2),  # Convert to MB\n            'throughput': len(samples) / np.mean(latencies)\n        }\n    \n    return performance_metrics\n","metadata":{"_uuid":"786fe5ef-e2a7-4669-88eb-a45829b75f9f","_cell_guid":"37a47959-5748-42a3-a0da-fd5a98ef615b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2024-12-06T12:00:47.436310Z","iopub.execute_input":"2024-12-06T12:00:47.436784Z","iopub.status.idle":"2024-12-06T12:00:47.445876Z","shell.execute_reply.started":"2024-12-06T12:00:47.436743Z","shell.execute_reply":"2024-12-06T12:00:47.445048Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# ============================================================================\n# Section 13: Model Export and Deployment Preparation\n# ============================================================================\n\"\"\"\nThis section handles model saving and export in multiple formats for different\nuse cases. We prepare the model for both research sharing and production\ndeployment, including comprehensive documentation of model characteristics.\n\"\"\"\n\ndef export_model():\n    \"\"\"\n    Prepares and exports the model in multiple formats with complete metadata\n    and documentation. This ensures reproducibility and ease of deployment.\n    \"\"\"\n    # Create export directory\n    export_dir = \"final_model\"\n    os.makedirs(export_dir, exist_ok=True)\n\n    # 1. Save for HuggingFace Hub\n    model.save_pretrained(export_dir)\n    tokenizer.save_pretrained(export_dir)\n\n    # 2. Save model configuration and metadata\n    config = {\n        \"model_name\": \"distilbert-ag-news\",\n        \"version\": \"1.0\",\n        \"architecture\": {\n            \"base_model\": \"distilbert-base-uncased\",\n            \"num_labels\": 4,\n            \"hidden_size\": 768\n        },\n        \"training_params\": train_config,\n        \"performance_metrics\": {\n            \"accuracy\": best_accuracy,\n            \"f1_score\": final_metrics['f1'],\n            \"training_time_minutes\": training_duration / 60\n        },\n        \"inference_benchmarks\": analyze_model_performance(),\n        \"label_mapping\": {\n            0: \"World\",\n            1: \"Sports\",\n            2: \"Business\",\n            3: \"Technology\"\n        }\n    }\n\n    with open(f\"{export_dir}/model_card.json\", \"w\") as f:\n        json.dump(config, f, indent=2)\n\n    # 3. Push to HuggingFace Hub\n    from huggingface_hub import HfApi\n    api = HfApi()\n    \n    try:\n        api.create_repo(\"ItsShakti/distilbert-ag-news\", private=False)\n        model.push_to_hub(\"ItsShakti/distilbert-ag-news\")\n        tokenizer.push_to_hub(\"ItsShakti/distilbert-ag-news\")\n        print(\"Successfully pushed model to HuggingFace Hub\")\n    except Exception as e:\n        print(f\"Error pushing to HuggingFace Hub: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:00:47.447068Z","iopub.execute_input":"2024-12-06T12:00:47.447325Z","iopub.status.idle":"2024-12-06T12:00:47.465462Z","shell.execute_reply.started":"2024-12-06T12:00:47.447289Z","shell.execute_reply":"2024-12-06T12:00:47.464733Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}